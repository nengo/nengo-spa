{
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Introduction to Nengo SPA\n",
      "\n",
      "This tutorial introduces the usage of Nengo SPA. It expects some basic familarity with [Nengo](https://pythonhosted.org/nengo/index.html). If you have used the legacy SPA implementation shipped with core Nengo, you might want to read this alternate introduction (TODO INSERT LINK)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We recommend to `import nengo_spa as spa`. (Note that this uses an underscore in the module name and is different from `nengo.spa` which refers to the legacy SPA module shipped with core Nengo.)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import matplotlib.pyplot as plt\n",
      "import nengo\n",
      "import nengo_spa as spa\n",
      "import numpy as np"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We will have to specify the dimensionality of the Semantic Pointers. To make it easy to change in all places, we define the variable *d* here and set it to 32. A dimensionality of 32 is on the lower end (in most actual models you will want to use at least 64 dimensions and we have been using up to 512 dimensions), but it makes the examples in this introduction run faster."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "d = 32"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Hello world\n",
      "\n",
      "Let us start with a very simple model to demonstrate the basic usage of Nengo SPA:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with spa.Network() as model:\n",
      "    stimulus = spa.Transcode('Hello', output_vocab=d)\n",
      "    state = spa.State(vocab=d)\n",
      "    nengo.Connection(stimulus.output, state.input)\n",
      "    p = nengo.Probe(state.output, synapse=0.01)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The first thing to notice is that instead of `nengo.Network`, we use `spa.Network` here. This allows use to more easily use Nengo's config system for Nengo SPA (something we will look at in more detail later). Then we instantiate two networks `spa.Transcode` and `spa.State`. These networks are aware of Semantic Pointer inputs and/or outputs. Such networks we also call (SPA) modules. The `Transcode` module is similar to a `nengo.Node`. Here it is given a the constant Semantic Pointer *Hello* and it will output this pointer during the whole simulation. The `State` module is a network of Nengo ensembles that is optimized for representing (unit-length) Semantic Pointers. Both of these modules have a *vocab*-like argument which is short for *vocabulary*. In the context of Nengo SPA a vocabulary is a set of Semantic Pointers with a certain dimensionality. Here we just use the default vocabulary with dimensionality *d*. The required Semantic Pointers (in this example *Hello*) will be automatically added to that vocabulary.\n",
      "\n",
      "Modules can be used like normal Nengo networks. Thus, we can create a connection from the output of *stimulus* to the input of *state* and then probe the output of *state*."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with nengo.Simulator(model) as sim:\n",
      "    sim.run(0.5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now, let us plot the probed data:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.plot(sim.trange(), sim.data[p])\n",
      "plt.xlabel(\"Time [s]\");"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This plot displays the raw vector components of the represented Semantic Pointer and is not extremely helpful. A useful function to get a more informative plot is `spa.similarity`. It takes the probe data and a vocabulary as arguments, and returns the similarity of the data to each Semantic Pointer in the vocabulary. We can access the vocabulary with the *vocab* attribute of the `State` module."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.plot(sim.trange(), spa.similarity(sim.data[p], state.vocab))\n",
      "plt.xlabel(\"Time [s]\")\n",
      "plt.ylabel(\"Similarity\")\n",
      "plt.legend(state.vocab, loc='best');"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    }
   ],
   "metadata": {}
  }
 ]
}

