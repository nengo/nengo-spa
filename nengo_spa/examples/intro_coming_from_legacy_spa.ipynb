{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transitioning nengo_spa coming from the core Nengo legacy SPA implementation\n",
    "\n",
    "This tutorial is intended for persons who are already familiar with the legacy Semantic Pointer Architecture (SPA) implementation that was shipped with core Nengo until at least version 2.4. Thus, it will not explain any of the background behind the SPA and will reference concepts used in the legacy implementation. If you are completely new to the SPA, you might want to start with a different tutorial (TODO link it here once written).\n",
    "\n",
    "## Why switch to nengo_spa?\n",
    "\n",
    "You might wonder why you should switch to nengo_spa, if you have been using the legacy SPA and it was working well for you. Here is a number of reasons to prefer nengo_spa:\n",
    "\n",
    "* Support for action rules of arbitrary complexity. Want to do `dot((role * filler + BiasVector) * tag, cmp) --> ...`? That is no problem with nengo_spa. Note that this includes two circular convolutions and a dot product of two non-fixed values; something not possible in this way with the legacy SPA implementation.\n",
    "* “Type safety” in action rules. If different vocabularies are combined an explicit conversion is required which prevents hard-to-track-down bugs. This conversion also makes it explicit how the conversion is done instead of just applying a fixed method that is not always appropriate.\n",
    "* The neural representations have been optimized to provide better accuracy. That means less neurons are needed to achieve the same performance which in turn can make simulations run faster. This improvement of accuracy is comparable to the results presented in [“Optimizing Semantic Pointer Representations for Symbol-Like Processing in Spiking Neural Networks”](http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0149928) which achieved improvements of up to 25 times. In contrast to that paper, the implementation used in nengo_spa is purely based on setting appropriate radii and distributions for evaluation points as well as intercepts which makes it a lot faster.\n",
    "* The neural representation has been optimized to allow the representation of the identity vector (with the option to turn this optimization off).\n",
    "* SPA networks can be used as and within normal Nengo networks. For example, instead of a basic and an SPA associative memory network, there is only one type of network that can be used in either case.\n",
    "* SPA networks can be nested.\n",
    "* Support for the Nengo config system.\n",
    "* Lots of fixed issues and in general less possibilities to do things wrong.\n",
    "\n",
    "## Importing nengo_spa\n",
    "\n",
    "To save typing it is recommended to `import nengo_spa as spa`. Note that this is only a very small difference to `import nengo.spa as spa` which imports the legacy SPA. In the following, it is assumed that you imported `nengo_spa` as `spa`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext nengo.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import nengo\n",
    "import nengo_spa as spa\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d = 32  # Default dimensionality to use in the examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rule 1 of using nengo_spa\n",
    "\n",
    "When using `nengo_spa`, use `spa.Network()` in any place where you would use a `nengo.Network()`. There isn't any downside to using `spa.Network()` and in this way you will not run into problems of using `nengo.Network()` where `spa.Network()` is required. That being said, if you have existing `nengo.Network`s (that do not use any SPA features), these can stay `nengo.Network`s. In other words, you will only have to touch code using the SPA to upgrade to nengo_spa; networks not using the SPA system may stay as they are.\n",
    "\n",
    "If you want to know when exactly `spa.Network()` is required, here are the conditions:\n",
    "\n",
    "1. If you build action rules, they have to be build in a `spa.Network()`.\n",
    "2. Each network referenced in an action rule has to be a  `spa.Network()` (if accessing `model.level1.level2`, all three `model`, `level1`, and `level2` need to be `spa.Network()`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A basic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with spa.Network() as model:\n",
    "    model.state = spa.State(d)\n",
    "    model.bind = spa.Bind(d)\n",
    "    spa.Actions('state = A * B', 'bind.input_a = state', 'bind.input_b = ~B').build()\n",
    "    p = nengo.Probe(model.bind.output, synapse=0.03)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This defines a basic SPA model. It is pretty similar to what you were to write in legacy SPA. But there are some fine details, so let us go through each of those.\n",
    "\n",
    "The first difference is that instead of `with spa.SPA() ...`, we are using `with spa.Network() ...`. There is no difference between the top-level `spa.SPA` and `spa.Module` anymore. Everything is just a `spa.Network`.\n",
    "\n",
    "The next two lines are the same as for the legacy SPA. You define the modules with the vocabulary dimension and assign them as attributes to the model. Note that you do not have to assign those modules as attributes as long as you are not trying to access them in action rules.\n",
    "\n",
    "The `spa.Actions` line is what replaces `nengo.spa.Cortical`. The cortical action rules are written in essentially the same way, though to access a specific input the typical Python dot notation is used instead of an underscore. Also note that the names of some of the inputs have changed. They follow a consistent naming scheme now: always starting with `input_` and you use the same name in action rules as in manually created Nengo connections. Finally, to create those cortical connections, you do not use a `Cortical` object, but the `build()` function on the `Actions` object which will build the connections within the currently active network. Note that the names in the actions rules are also relative to the currently active network and need to refer to assigned `spa.Network` attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with nengo.Simulator(model) as sim:\n",
    "    sim.run(1.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us plot the result. Note that we can access the *d*-dimensional default vocabulary with `model.vocabs[d]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(sim.trange(), spa.similarity(sim.data[p], model.vocabs[d]))\n",
    "plt.xlabel(\"Time [s]\")\n",
    "plt.ylabel(\"Similarity\")\n",
    "plt.legend(model.vocabs[d].keys(), loc='best')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is another detail you might notice here: the `keys` attribute on the vocabularies is now a function. This is to have `Vocabulary` adhere to the usual Python API of dictionaries and mapping types."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode, Decode, Transcode\n",
    "\n",
    "In the previous example, input was provided directly in the action rules. But this does not allow for time-varying inputs. The legacy SPA `Input` has been replaced with `spa.Encode` which has an API more similar to classic `nengo.Nodes`. It takes either a constant value or a function which may return any of the following:\n",
    "\n",
    "* A string that is parsed as a semantic pointer.\n",
    "* A `SemanticPointer` instance.\n",
    "* A NumPy array.\n",
    "\n",
    "The next examples demonstrates this. It also manually specifies a vocabulary, but ignore this for now as the changes to `Vocabulay` will be discussed later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab = spa.Vocabulary(d, strict=False)\n",
    "\n",
    "def stimulus_fn(t):\n",
    "    if t < 0.5:\n",
    "        return 'A * B'  # Return string to be parsed\n",
    "    elif t < 1.:\n",
    "        return vocab.parse('C * B')  # Return SemanticPointer instance\n",
    "    else:\n",
    "        return np.zeros(d)  # Return a numpy array\n",
    "\n",
    "with spa.Network() as model:\n",
    "    model.state = spa.State(vocab)\n",
    "    model.bind = spa.Bind(vocab)\n",
    "    model.input = spa.Encode(stimulus_fn, vocab)\n",
    "    spa.Actions('state = input', 'bind.input_a = state', 'bind.input_b = ~B').build()\n",
    "    p = nengo.Probe(model.bind.output, synapse=0.03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with nengo.Simulator(model) as sim:\n",
    "    sim.run(1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(sim.trange(), spa.similarity(sim.data[p], vocab))\n",
    "plt.xlabel(\"Time [s]\")\n",
    "plt.ylabel(\"Similarity\")\n",
    "plt.legend(vocab.keys(), loc='best')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One thing that is possible with `nengo.Node`, but not with `spa.Encode` (nor with the old `spa.Input`), is to provide an input from the network. If you want to do this, you can now use the `spa.Transcode` module. Its output function gets three inputs: the current simulation time, a `SemanticPointer` instance of the input, and the input vocabulary. To create a `Transcode` instance, the dimensionality (or vocabulary) has to be passed in twice. The first specifies the input vocabulary (the one passed to the output function), the second one specifies the output vocabulary that will be used to pares the function's output.\n",
    "\n",
    "In the following example we compute the circular convolution with `~B` in math instead of a neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cconv(t, p, vocab):\n",
    "    return vocab.parse('~B') * p\n",
    "\n",
    "with spa.Network() as model:\n",
    "    model.state = spa.State(d)\n",
    "    model.bind = spa.Transcode(cconv, d, d)\n",
    "    model.input = spa.Encode('A * B', d)\n",
    "    spa.Actions('state = input', 'bind = state').build()\n",
    "    p = nengo.Probe(model.bind.output, synapse=0.03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with nengo.Simulator(model) as sim:\n",
    "    sim.run(1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(sim.trange(), spa.similarity(sim.data[p], model.vocabs[d]))\n",
    "plt.xlabel(\"Time [s]\")\n",
    "plt.ylabel(\"Similarity\")\n",
    "plt.legend(model.vocabs[d].keys(), loc='best')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Besides `Encode` and `Transcode`,  there is a third module called `Decode`. It accepts an input like with same function arguments as for `Transcode`, but the function cannot provide any input to the network.\n",
    "\n",
    "As a recap: `Encode` encodes Semantic Pointers into neural activity, `Decode` decodes Semantic Pointers from neural activity, and `Transcode` decodes Semantic Pointers from neural activity and reencodes them after some transformation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Action rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have already seen how to create cortical action rules with nengo_spa. The next example shows how to add action rules implemented through the basal ganglia-thalamus loop. It is the classical routing through a sequence example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def start(t):\n",
    "    if t < 0.05:\n",
    "        return 'A'\n",
    "    else:\n",
    "        return '0'\n",
    "\n",
    "with spa.Network() as model:\n",
    "    model.state = spa.State(d)\n",
    "    model.input = spa.Encode(start, d)\n",
    "    \n",
    "    spa.Actions(\n",
    "        'state = input',\n",
    "        'dot(state, A) --> state = B',\n",
    "        'dot(state, B) --> state = C',\n",
    "        'dot(state, C) --> state = D',\n",
    "        'dot(state, D) --> state = E',\n",
    "        'dot(state, E) --> state = A'\n",
    "    ).build()\n",
    "    \n",
    "    p = nengo.Probe(model.state.output, synapse=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with nengo.Simulator(model) as sim:\n",
    "    sim.run(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(sim.trange(), spa.similarity(sim.data[p], model.vocabs[d]))\n",
    "plt.xlabel(\"Time [s]\")\n",
    "plt.ylabel(\"Similarity\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that you can freely mix cortical and basal ganglia rules. There is also no need to manually create the basal ganglia and thalamus. This happens automatically. If you build multiple `Actions` objects, multiple instances will be created that operate in parallel. So in most cases you want to collect all you rules in a single `Actions` object. In case you need access to the created basal ganglia and thalamus (e.g. for plotting as in the next example), those objects are returned from the `build` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def start(t):\n",
    "    if t < 0.05:\n",
    "        return 'A'\n",
    "    else:\n",
    "        return '0'\n",
    "\n",
    "with spa.Network() as model:\n",
    "    model.state = spa.State(d)\n",
    "    model.input = spa.Encode(start, d)\n",
    "    \n",
    "    actions = spa.Actions(\n",
    "        'state = input',\n",
    "        'dot(state, A) --> state = B',\n",
    "        'dot(state, B) --> state = C',\n",
    "        'dot(state, C) --> state = D',\n",
    "        'dot(state, D) --> state = E',\n",
    "        'dot(state, E) --> state = A'\n",
    "    )\n",
    "    model.bg, model.thalamus, _ = actions.build()\n",
    "    \n",
    "    p_thalamus = nengo.Probe(model.thalamus.actions.output, synapse=0.01)\n",
    "    p_utility = nengo.Probe(model.bg.input, synapse=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with nengo.Simulator(model) as sim:\n",
    "    sim.run(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(sim.trange(), sim.data[p_thalamus])\n",
    "plt.legend([a.effects for a in actions], fontsize='x-small')\n",
    "plt.ylabel('Thalamus output')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(sim.trange(), sim.data[p_utility])\n",
    "plt.legend([getattr(a, 'condition', '<cortical>') for a in actions], fontsize='x-small', loc='right')\n",
    "plt.ylabel('Utility')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Opposed to the legacy SPA, nengo_spa allows arbitrarily complex actions rules. In the following example we define dot products between two states and dynamic circular convolutions. All required networks will be created automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with spa.Network() as model:\n",
    "    model.state_ab = spa.State(d)\n",
    "    model.state_a = spa.State(d)\n",
    "    model.state_b = spa.State(d)\n",
    "    model.out = spa.State(d)\n",
    "    \n",
    "    actions = spa.Actions(\n",
    "        'dot(state_ab, state_a * state_b) --> out = state_ab * ~B',\n",
    "        '0.5 --> out = C',\n",
    "        'state_ab = A * B',\n",
    "        'state_a = A',\n",
    "        'state_b = state_ab * ~state_a',\n",
    "    )\n",
    "    model.bg, model.thalamus, constructed = actions.build()\n",
    "    \n",
    "    p = nengo.Probe(model.out.output, synapse=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with nengo.Simulator(model) as sim:\n",
    "    sim.run(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(sim.trange(), spa.similarity(sim.data[p], model.vocabs[d]))\n",
    "plt.xlabel(\"Time [s]\")\n",
    "plt.ylabel(\"Similarity\")\n",
    "plt.legend(model.vocabs[d].keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that there is no automatic sharing of networks in the action rules. If, for example, you define the same circular convolution in there, two such networks will be created.\n",
    "\n",
    "If you have nengo_gui installed, it can be used to take a look at all the things that get created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    from nengo_gui.ipython import IPythonViz\n",
    "    vis = IPythonViz(model)\n",
    "except (ImportError, AttributeError):\n",
    "    print(\"GUI not installed or code not executed in Jupyter notebook.\")\n",
    "    vis = None\n",
    "vis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way to access all the created objects are the three values returned by `build()`. The first two are the basal ganglia and thalamus as already discussed and give access to all related networks and connections. All the remaining objects that were created are provided in a dictionary `constructed` returned as third value. The dictionary uses nodes in the internally constructed syntax tree to index lists of objects created for that node (these nodes are not related to `nengo.Node`!). Admittedly, this is not the most convenient way to access things and might change in the future. But for now it at least gives a possibility to access those objects if required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "pprint(constructed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vocabularies\n",
    "\n",
    "Nengo_spa behaves a lot like legacy SPA when providing dimensionalities only. Vocabularies will implicitely be created according to the specified dimensions and Semantic Pointers will be automatically added. When creating a vocabulary explicitely, things are a little bit different. In that case the vocabulary will be in strict-mode by default. That means an exception will be raised when trying to parse a Semantic Pointer that is not in the vocabulary. This is to prevent accidentally adding new Semantic Pointers (something that tendend to happen with the associative memmory in legacy SPA) and can make it easier to notice typing errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nengo_spa.exceptions import SpaParseError\n",
    "vocab = spa.Vocabulary(d)\n",
    "try:\n",
    "    vocab.parse('A')\n",
    "except SpaParseError as err:\n",
    "    print(err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All Semantic Pointers have to be added to the vocabulary with either `add` or the new `populate` method before they are recognized by `parse`. You can add multiple pointers add once by separating them with a semicolon in `populate`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = spa.Vocabulary(d)\n",
    "vocab.add('A', vocab.create_pointer())\n",
    "vocab.populate('B; C')\n",
    "vocab.parse('A + B + C')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you prefer to automatically add unknown vectors, you can disable strict mode. This can be especially useful when experimenting with initial ideas in the GUI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = spa.Vocabulary(d, strict=False)\n",
    "vocab.parse('A')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The new `populate` method is much more powerful than adding pointers with `parse`. For example you can use existing Semantic pointers to construct new ones and you can use transforms as `normalized()` and `unitary()` to make vectors unit length or normalized. Note that a simple Semantic Pointer will be normalized, but you need to explicitely do this when constructing a pointer out of others.\n",
    "\n",
    "In the following example we create a vocabulary with four pointers *A*, *B*, *C*, and *D*. *A* is made unitary, D is constructed from other vectors and normalized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab = spa.Vocabulary(d)\n",
    "vocab.populate('A.unitary(); B; C; D = (A * B + C).normalized()')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another new and sometimes useful method is `parse_n` which allows to parse multiple Semantic Pointer expressions at once. This can be useful for programatically constructing a list of pointers for plotting. The following example demonstrates that for all convolution pairs. It also shows that when using a predefined vocabulary, the modules will obtain their dimensionality from that vocabulary. No need to pass dimensionality and vocabulary anymore!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab = spa.Vocabulary(d)\n",
    "vocab.populate('A; B; C')\n",
    "\n",
    "with spa.Network() as model:\n",
    "    model.state = spa.State(vocab)\n",
    "    spa.Actions('state = A * B').build()\n",
    "    p = nengo.Probe(model.state.output, synapse=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with nengo.Simulator(model) as sim:\n",
    "    sim.run(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nengo_spa.examine import pairs\n",
    "plot_keys = pairs(vocab)\n",
    "plot_vectors = vocab.parse_n(*plot_keys)\n",
    "\n",
    "plt.plot(sim.trange(), spa.similarity(sim.data[p], plot_vectors))\n",
    "plt.xlabel(\"Time [s]\")\n",
    "plt.ylabel(\"Similarity\")\n",
    "plt.legend(plot_keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another feature of nengo_spa is “type-safety” in the sense that you cannot just connect things with different vocabularies in action rules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nengo_spa.exceptions import SpaTypeError\n",
    "\n",
    "v1 = spa.Vocabulary(d)\n",
    "v1.populate('A; B')\n",
    "v2 = spa.Vocabulary(d)\n",
    "v2.populate('B; C')\n",
    "\n",
    "try:\n",
    "    with spa.Network() as model:\n",
    "        model.state1 = spa.State(v1)\n",
    "        model.state2 = spa.State(v2)\n",
    "        spa.Actions('state1 = state2').build()\n",
    "except SpaTypeError as err:\n",
    "    print(err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to do this, we have to be explicit about how the conversion between the vocabularies is supposed to be happen. The first option (if both vocabularies have the same dimensionality) is to just reinterpret the Semantic Pointer in the other vocabulary. Because the vectors in both vocabularies are independent (by default) the *A* from `v2` will be different from *A* in `v1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "v1 = spa.Vocabulary(d)\n",
    "v1.populate('A; B')\n",
    "v2 = spa.Vocabulary(d)\n",
    "v2.populate('A; B')\n",
    "\n",
    "with spa.Network() as model:\n",
    "    model.state1 = spa.State(v1)\n",
    "    model.state2 = spa.State(v2)\n",
    "    spa.Actions('state1 = reinterpret(state2)', 'state2 = A').build()\n",
    "    p = nengo.Probe(model.state1.output, synapse=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with nengo.Simulator(model) as sim:\n",
    "    sim.run(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(sim.trange(), v1['A'].dot(sim.data[p].T))\n",
    "plt.plot(sim.trange(), v2['A'].dot(sim.data[p].T))\n",
    "plt.xlabel(\"Time [s]\")\n",
    "plt.ylabel(\"Similarity\")\n",
    "plt.legend([\"v1['A']\", \"v2['A']\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the value in `state2` is still similar to `v2`'s *A* even though `state2` uses `v1` as vocabulary.\n",
    "\n",
    "The second choice to convert between vocabularies is `translate` which will construct a transformation matrix to convert from one vocabulary to the other based on the Semantic Pointer names. This also works with vocabularies that do not match in dimensionality, but the target vocabulary should contain all keys of the source vocabulary. If this is not the case, you will get either a warning or an exception depending on whether you are using strict-mode vocabularies. You can also use the `populate=True` argument to `translate` to have all missing keys added to the target vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "v1 = spa.Vocabulary(d)\n",
    "v1.populate('A; B')\n",
    "v2 = spa.Vocabulary(d)\n",
    "v2.populate('A; B')\n",
    "\n",
    "with spa.Network() as model:\n",
    "    model.state1 = spa.State(v1)\n",
    "    model.state2 = spa.State(v2)\n",
    "    spa.Actions('state1 = translate(state2)', 'state2 = A').build()\n",
    "    p = nengo.Probe(model.state1.output, synapse=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with nengo.Simulator(model) as sim:\n",
    "    sim.run(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(sim.trange(), v1['A'].dot(sim.data[p].T))\n",
    "plt.plot(sim.trange(), v2['A'].dot(sim.data[p].T))\n",
    "plt.xlabel(\"Time [s]\")\n",
    "plt.ylabel(\"Similarity\")\n",
    "plt.legend([\"v1['A']\", \"v2['A']\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## nengo_spa and the config system\n",
    "\n",
    "One of the major improvements in nengo_spa is the extensive use of Nengo's config system. For example it allows to set the vocab for all states globally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with spa.Network() as model:\n",
    "    model.config[spa.State].vocab = d\n",
    "    model.state1 = spa.State()\n",
    "    model.state2 = spa.State()\n",
    "    spa.Actions('state2 = state1', 'state1 = A').build()\n",
    "    p = nengo.Probe(model.state2.output, synapse=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with nengo.Simulator(model) as sim:\n",
    "    sim.run(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(sim.trange(), spa.similarity(sim.data[p], model.vocabs[d]))\n",
    "plt.xlabel(\"Time [s]\")\n",
    "plt.ylabel(\"Similarity\")\n",
    "plt.legend(model.vocabs[d].keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The config system can also be used to set neuron numbers, subdimensions, and various other parameters, in particular of objects created when building action rules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def start(t):\n",
    "    if t < 0.1:\n",
    "        return 'A'\n",
    "    else:\n",
    "        return '0'\n",
    "\n",
    "with spa.Network() as model:\n",
    "    model.config[spa.State].neurons_per_dimension = 10\n",
    "    model.config[spa.State].subdimensions = 1\n",
    "    model.config[spa.Thalamus].synapse_channel = nengo.Lowpass(0.1)\n",
    "    \n",
    "    model.state = spa.State(d)\n",
    "    model.input = spa.Encode(start, d)\n",
    "    spa.Actions(\n",
    "        'state = input',\n",
    "        'dot(state, A) --> state = 2 * B',\n",
    "        'dot(state, B) --> state = 2 * C',\n",
    "        'dot(state, C) --> state = 2 * A',\n",
    "    ).build()\n",
    "\n",
    "    p = nengo.Probe(model.state.output, synapse=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with nengo.Simulator(model) as sim:\n",
    "    sim.run(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(sim.trange(), spa.similarity(sim.data[p], model.vocabs[d]))\n",
    "plt.xlabel(\"Time [s]\")\n",
    "plt.ylabel(\"Similarity\")\n",
    "plt.legend(model.vocabs[d].keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semantic Pointers\n",
    "\n",
    "The `SemanticPointer` class has become immutable in nengo_spa to avoid accidental modifiction of Semantic Pointers. Whenever an operation is applied to a `SemanticPointer` (for example `SemanticPointer(d) + SemanticPointer(d)` or `SemanticPointer(d).normalized()` a new instance will be created.\n",
    "\n",
    "To facilitate mathematical analysis of encoding schemes some special vectors are predefined:\n",
    "\n",
    "* `nengo_spa.pointer.Identity(d)` gives the identity vector for circular convolution.\n",
    "* `nengo_spa.pointer.Zero(d)` gives the vector of all zeros (absorbing element for circular convolution).\n",
    "* `nengo_spa.pointer.AbsorbingElement(d)` gives a vector that destroys all information under circluar convolution except for a DC offset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Representing identity\n",
    "\n",
    "In nengo_spa `spa.State()` is optimized to allow the representation of the identity vector. This is not always necessary as in many models the identity never needs to represented. With `represent_identity=False` this optimization can be disabled. This can make the representation for non-identity vectors slightly better. It also simplifies the internal structure of `spa.State()` which can be helpful for applying learning rules."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## New associative memory classes\n",
    "\n",
    "To reduce the number of arguments of the associative memory class it has been split into two classes. `spa.ThresholdingAssocMem` is the applying a simple threshold, `spa.WTAAssocMem` performs a winner-take-all clean-up with lateral inhibitory connections. There is also a new type of associative memory `spa.IAAssocMem` based on independent accumulators, that also exhibits winner-take-all behaviour, but with different dynamics. (TODO link CogSci paper once published)\n",
    "\n",
    "To implement auto-associative memories, the `input_keys` and `output_keys` arguments have been replaced by a single `mapping` arguments.\n",
    "\n",
    "TODO link associative memory documentation/tutorial."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clean",
   "language": "python",
   "name": "clean"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "widgets": {
   "state": {
    "0040372fe37147488e7daa8b661891e7": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "02b73315901d4bd39049d7900cf43efa": {
     "views": [
      {
       "cell_index": 14
      }
     ]
    },
    "049d0e4f2e6f4c39bbf232951fc1ae66": {
     "views": [
      {
       "cell_index": 18
      }
     ]
    },
    "121e589a2e164abf8262f7dd04819b7f": {
     "views": [
      {
       "cell_index": 18
      }
     ]
    },
    "1b213b6826544b7c90ce00dc1e291db8": {
     "views": [
      {
       "cell_index": 66
      }
     ]
    },
    "2183402daccf42aa8faf9b4b5cd2a482": {
     "views": [
      {
       "cell_index": 48
      }
     ]
    },
    "23cd51e402b6429abcf87b15e0c6f57e": {
     "views": [
      {
       "cell_index": 58
      }
     ]
    },
    "26586c4f7caa4a7cb618cb942d568a9f": {
     "views": [
      {
       "cell_index": 24
      }
     ]
    },
    "2cf7a954f4f94ffebdf901ffa53f3041": {
     "views": [
      {
       "cell_index": 54
      }
     ]
    },
    "364c7fc99ce94944b5d4617fea76a943": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "38ae9ab81b25460caa048d754fda6452": {
     "views": [
      {
       "cell_index": 14
      }
     ]
    },
    "40f1873e62754426bce9edb596108d83": {
     "views": [
      {
       "cell_index": 58
      }
     ]
    },
    "4c5d35e90c1b4bb3813b2d81fc7a0a66": {
     "views": [
      {
       "cell_index": 18
      }
     ]
    },
    "5a7b973ddc80432f9f0122e25d94a5df": {
     "views": [
      {
       "cell_index": 18
      }
     ]
    },
    "61dad039b7e94f6cae57450b36f56637": {
     "views": [
      {
       "cell_index": 32
      }
     ]
    },
    "6643a35e667946c788a1b9d08a281904": {
     "views": [
      {
       "cell_index": 28
      }
     ]
    },
    "6890dc50db4f4c779d247bf52f2f78dd": {
     "views": [
      {
       "cell_index": 28
      }
     ]
    },
    "68aba242a2d14559a27f717c3f85f8a0": {
     "views": [
      {
       "cell_index": 54
      }
     ]
    },
    "6ac99955e0f74af39fb06aea98a68f0e": {
     "views": [
      {
       "cell_index": 48
      }
     ]
    },
    "6d0cb48f8dd64e0b998ade21117851ad": {
     "views": [
      {
       "cell_index": 62
      }
     ]
    },
    "71c68e5c9fa74eef8992e02f0694362a": {
     "views": [
      {
       "cell_index": 24
      }
     ]
    },
    "8824f375b7564983bc877ed5f09e0743": {
     "views": [
      {
       "cell_index": 66
      }
     ]
    },
    "8954c999273d4005aa37692fc2f83d89": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "8b9fa3566e564b64b37af89574b77803": {
     "views": [
      {
       "cell_index": 32
      }
     ]
    },
    "8d4364a0ef4b4437be2b7e9dba00fab5": {
     "views": [
      {
       "cell_index": 62
      }
     ]
    },
    "95334ec1883b4a0a808987bfd0b21c35": {
     "views": [
      {
       "cell_index": 28
      }
     ]
    },
    "ad8a7d373a5345dd965d5fd6ab487682": {
     "views": [
      {
       "cell_index": 32
      }
     ]
    },
    "b514cc407e144e7d85fab89ad29c641d": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "c2c2399d8e1e4a3ca60210d461f8ca49": {
     "views": [
      {
       "cell_index": 14
      }
     ]
    },
    "c65f5474fa0347bfaf5667a32200dbaf": {
     "views": [
      {
       "cell_index": 28
      }
     ]
    },
    "cb636fee52f447bcb48953a4a70ad9a8": {
     "views": [
      {
       "cell_index": 24
      }
     ]
    },
    "e24f0bf29f4643f28fc2ea065d8989e1": {
     "views": [
      {
       "cell_index": 32
      }
     ]
    },
    "e8f8062038b049aab475820237291f30": {
     "views": [
      {
       "cell_index": 14
      }
     ]
    },
    "fd5590dc25164e379649565afd731d77": {
     "views": [
      {
       "cell_index": 24
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

