{
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Introduction to Nengo SPA\n",
      "\n",
      "This tutorial introduces the usage of Nengo SPA. It expects some basic familarity with [Nengo](https://www.nengo.ai/nengo/). If you have used the legacy SPA implementation shipped with core Nengo, you might want to read [this alternate introduction](intro_coming_from_legacy_spa.ipynb)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We recommend to `import nengo_spa as spa`. (Note that this uses an underscore in the module name and is different from `nengo.spa` which refers to the legacy SPA module shipped with core Nengo.)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from __future__ import print_function"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import matplotlib.pyplot as plt\n",
      "import nengo\n",
      "import nengo_spa as spa\n",
      "import numpy as np"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We will have to specify the dimensionality of the Semantic Pointers. To make it easy to change in all places, we define the variable *d* here and set it to 32. A dimensionality of 32 is on the lower end (in most actual models you will want to use at least 64 dimensions and we have been using up to 512 dimensions), but it makes the examples in this introduction run faster."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "d = 32"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Hello world\n",
      "\n",
      "Let us start with a very simple model to demonstrate the basic usage of Nengo SPA:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with spa.Network() as model:\n",
      "    stimulus = spa.Transcode('Hello', output_vocab=d)\n",
      "    state = spa.State(vocab=d)\n",
      "    nengo.Connection(stimulus.output, state.input)\n",
      "    p = nengo.Probe(state.output, synapse=0.01)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The first thing to notice is that instead of `nengo.Network`, we use `spa.Network` here. This allows use to more easily use Nengo's config system for Nengo SPA (something we will look at in more detail later). Then we instantiate two networks `spa.Transcode` and `spa.State`. These networks are aware of Semantic Pointer inputs and/or outputs. Such networks we also call (SPA) modules. The `Transcode` module is similar to a `nengo.Node`. Here it is given a the constant Semantic Pointer *Hello* and it will output this pointer during the whole simulation. The `State` module is a network of Nengo ensembles that is optimized for representing (unit-length) Semantic Pointers. Both of these modules have a *vocab*-like argument which is short for *vocabulary*. In the context of Nengo SPA a vocabulary is a set of Semantic Pointers with a certain dimensionality. Here we just use the default vocabulary with dimensionality *d*. The required Semantic Pointers (in this example *Hello*) will be automatically added to that vocabulary.\n",
      "\n",
      "Modules can be used like normal Nengo networks. Thus, we can create a connection from the output of *stimulus* to the input of *state* and then probe the output of *state*."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with nengo.Simulator(model) as sim:\n",
      "    sim.run(0.5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now, let us plot the probed data:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.plot(sim.trange(), sim.data[p])\n",
      "plt.xlabel(\"Time [s]\");"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This plot displays the raw vector components of the represented Semantic Pointer and is not extremely helpful. A useful function to get a more informative plot is `spa.similarity`. It takes the probe data and a vocabulary as arguments, and returns the similarity of the data to each Semantic Pointer in the vocabulary. We can access the vocabulary with the *vocab* attribute of the `State` module."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.plot(sim.trange(), spa.similarity(sim.data[p], state.vocab))\n",
      "plt.xlabel(\"Time [s]\")\n",
      "plt.ylabel(\"Similarity\")\n",
      "plt.legend(state.vocab, loc='best');"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We see that input Pointer is successfully represented."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## SPA syntax\n",
      "\n",
      "One of the main features of `nengo_spa` is a special syntax that makes it easier to construct large SPA models. Let us demonstrate this with a slightly more complicated example where we take represent a scene by a Semantic Pointer `BLUE * CIRCLE + RED * SQUARE` (`*` denotes circular convolution here) and use another input to selectively retrieve the color of one of the objects."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with spa.Network() as model:\n",
      "    scene = spa.Transcode('BLUE * CIRCLE + RED * SQUARE', output_vocab=d)\n",
      "    query = spa.Transcode(lambda t: 'CIRCLE' if t < 0.25 else 'SQUARE', output_vocab=d)\n",
      "    result = spa.State(vocab=d)\n",
      "    \n",
      "    scene * ~query >> result\n",
      "    \n",
      "    p = nengo.Probe(result.output, synapse=0.01)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We see that the `Transcode` object also accepts functions like a Nengo `Node`. But the really interesting line is:\n",
      "\n",
      "```python\n",
      "scene * ~query >> result\n",
      "```\n",
      "\n",
      "This line is all that is needed to construct a network inverting a circular convolution (`*` is the circular convolution, `~` inverts `query`), connect `scene` and `query` as inputs, and then connect the output to result (`>>`).\n",
      "\n",
      "If we run the model, we see that is successfully decodes `BLUE` and `RED`."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with nengo.Simulator(model) as sim:\n",
      "    sim.run(0.5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.plot(sim.trange(), spa.similarity(sim.data[p], result.vocab))\n",
      "plt.xlabel(\"Time [s]\")\n",
      "plt.ylabel(\"Similarity\")\n",
      "plt.legend(result.vocab, loc='best');"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Besides circular convolution (`*`) and the approximate inverse (`~`), you can use `*` also to scale with vectors with a fixed scalar or multiply to scalars, `+` and `-` to add and subtract Semantic Pointers, and `@` to compute a dot product if you are using Python >= 3.5. To compute a dot product with older python versions use the `spa.dot` function."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Symbols\n",
      "\n",
      "So far we used the `Transcode` network to provide fixed inputs to the network. But there is a second method that sometimes means less typing."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with spa.Network() as model:\n",
      "    query = spa.Transcode(lambda t: 'CIRCLE' if t < 0.25 else 'SQUARE', output_vocab=d)\n",
      "    result = spa.State(vocab=d)\n",
      "    \n",
      "    (spa.sym.BLUE * spa.sym.CIRCLE + spa.sym.RED * spa.sym.SQUARE) * ~query >> result\n",
      "    \n",
      "    p = nengo.Probe(result.output, synapse=0.01)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The `spa.sym` object is a special object on which you can access arbitrary attributes that will magically return symbolic representations of Semantic Pointers that can be combined with the usual operators among each other or with SPA modules which will cause the required neural networks to be implemented."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Action selection\n",
      "\n",
      "Often it is necessary to choose one action out of a number of potential actions. This can be done with the `ActionSelection` object. It is used as a context manager und within its context `ifmax` function calls define the potential actions. You can pass an optional name as first argument to `ifmax`, but you don't have to. The next argument is an expression that determines the utility value for the action being defined. The remaining arguments define where things should be routed, if the action's utility value is the highest of all the actions defined in the `ActionSelection` context.\n",
      "\n",
      "In this example, we use this to cycle through a sequence of Semantic Pointers. Initially, we feed `A` into `state` to start things off and then we compute the dot product of the Semantic Pointer in `state` with the candidates and feed the next Semantic Pointer in the sequence to `state` accordingly."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def start(t):\n",
      "    if t < 0.05:\n",
      "        return 'A'\n",
      "    else:\n",
      "        return '0'\n",
      "\n",
      "with spa.Network() as model:\n",
      "    state = spa.State(d)\n",
      "    spa_input = spa.Transcode(start, output_vocab=d)\n",
      "    \n",
      "    spa_input >> state\n",
      "    with spa.ActionSelection():\n",
      "        spa.ifmax(spa.dot(state, spa.sym.A),\n",
      "            spa.sym.B >> state)\n",
      "        spa.ifmax(spa.dot(state, spa.sym.B),\n",
      "            spa.sym.C >> state)\n",
      "        spa.ifmax(spa.dot(state, spa.sym.C),\n",
      "            spa.sym.D >> state)\n",
      "        spa.ifmax(spa.dot(state, spa.sym.D),\n",
      "            spa.sym.E >> state)\n",
      "        spa.ifmax(spa.dot(state, spa.sym.E),\n",
      "            spa.sym.A >> state)\n",
      "    \n",
      "    p = nengo.Probe(state.output, synapse=0.01)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with nengo.Simulator(model) as sim:\n",
      "    sim.run(0.5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.plot(sim.trange(), spa.similarity(sim.data[p], state.vocab))\n",
      "plt.legend(state.vocab.keys())\n",
      "plt.xlabel(\"Time [s]\")\n",
      "plt.ylabel(\"Similarity\");"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Using Transcode for computation\n",
      "\n",
      "As mentioned before, the `Transcode` object is the analog to the Nengo `Node`. That means you can also use it for computation implemented in Python code. Let us take one of the previous examples, but implement the approximate inverse of the circular convolution in Python code. Note that `scene` and `x` are both SPA symbols, so the operations `*` and `~` still apply as defined in the SPA syntax."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with spa.Network() as model:\n",
      "    scene = spa.sym.BLUE * spa.sym.CIRCLE + spa.sym.RED * spa.sym.SQUARE\n",
      "    unbind = spa.Transcode(lambda t, x: scene * ~x, input_vocab=d, output_vocab=d)\n",
      "    query = spa.Transcode(lambda t: 'CIRCLE' if t < 0.25 else 'SQUARE', output_vocab=d)\n",
      "    result = spa.State(vocab=d)\n",
      "    \n",
      "    query >> unbind\n",
      "    unbind >> result\n",
      "    \n",
      "    p = nengo.Probe(result.output, synapse=0.01)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with nengo.Simulator(model) as sim:\n",
      "    sim.run(0.5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.plot(sim.trange(), spa.similarity(sim.data[p], result.vocab))\n",
      "plt.xlabel(\"Time [s]\")\n",
      "plt.ylabel(\"Similarity\")\n",
      "plt.legend(result.vocab, loc='best');"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Using the config system with Nengo SPA\n",
      "\n",
      "When building networks with Nengo SPA there is a number of parameters that will be set to predetermined values. Sometimes you might want to change these values. That can be done with the Nengo config system. In this example, we change the number of neurons implementing a `State`. Because we reduce the number of neurons by a lot, the start of the result will look much noisier."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with spa.Network() as model:\n",
      "    model.config[spa.State].neurons_per_dimension = 10\n",
      "    \n",
      "    state = spa.State(d)\n",
      "    spa.sym.A >> state\n",
      "\n",
      "    p = nengo.Probe(state.output, synapse=0.01)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with nengo.Simulator(model) as sim:\n",
      "    sim.run(0.5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.plot(sim.trange(), spa.similarity(sim.data[p], state.vocab))\n",
      "plt.legend(state.vocab.keys())\n",
      "plt.xlabel(\"Time [s]\")\n",
      "plt.ylabel(\"Similarity\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 24
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Vocabularies\n",
      "\n",
      "Sometimes you will have sets of unrelated Semantic Pointers. It can be useful to keep them in distinct groups called *vocabularies*. You can create a vocabulary by instantiating a `spa.Vocabulary` object with the desired dimensionality. To fill it with Semantic Pointers, you can use the `populate` method which takes a string of Semantic Pointer names separated with semicolons. The vocabulary object will try to keep the maximum similarity between all pointers below a certain threshold (0.1 by default)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "vocab = spa.Vocabulary(32)\n",
      "vocab.populate('BLUE; RED; CIRCLE; SQUARE')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 25
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "If you happen to have a Python list of names, that can also be passed easily to `populate` with a little trick:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "list_of_names = ['GREEN', 'YELLOW']\n",
      "vocab.populate(';'.join(list_of_names))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 26
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "You can also construct Semantic Pointers out of others."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "vocab.populate('''\n",
      "    PURPLE = BLUE + RED;\n",
      "    COLOR_MIX_1 = 0.8 * GREEN + 0.5 * YELLOW;\n",
      "    SQUARING_THE_CIRCLE = CIRCLE * SQUARE''')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 27
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Note that these Semantic Pointers will not be normalized to unit length. If you desire so, call `normalized()` on the constructed pointer. You can also use `unitary()` to get unitary Semantic Pointers."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "vocab.populate('''\n",
      "    NORM_PURPLE = (BLUE + RED).normalized();\n",
      "    UNITARY1.unitary();\n",
      "    UNITARY2 = (SQUARE * CIRCLE).unitary()''')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 28
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Sometimes you might already have a vector that you want to use as a Semantic Pointer instead of a randomly constructed one. These can be added to a vocabulary with the `add` method. Note, that this will not ensure the maximum similarity constraint."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "v = np.zeros(32)\n",
      "vocab.add('NULL', v)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 29
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Vocabularies work like dictionaries. That means you can retrieve all contained Semantic Pointers with `keys()` and use indexing with Semantic Pointer names to retrieve specific pointers as `SemanticPointer` objects. Those specific pointers support the associated arithmetic operations (e.g., `+` for superposition, `*` for circular convolution). They can also be used in the SPA syntax, for example to provide them as input to modules. To access the actual vector use the `v` attribute."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(list(vocab.keys()))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "blue = vocab['BLUE']\n",
      "print(blue.v)\n",
      "print((blue * vocab['RED']).v)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 31
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "A vocabulary can also parse more complex expressions and return the resulting Semantic Pointer."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(vocab.parse('BLUE * RED').v)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 32
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Creating subsets of vocabularies\n",
      "\n",
      "In some cases it is useful to create a smaller subset from an existing vocabulary. This subset will use exactly the same vectors as in the original vocabulary."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "just_colors = vocab.create_subset(['BLUE', 'RED', 'GREEN', 'YELLOW', 'PURPLE'])\n",
      "print(list(just_colors.keys()))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 33
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Using vocabularies\n",
      "\n",
      "To use a manually created vocabulary in a model, pass it instead of the dimensionality to the module."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with spa.Network() as model:\n",
      "    state = spa.State(vocab)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 34
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Strict mode\n",
      "\n",
      "Vocabularies that are manually instantiated will be in strict mode per default. That means trying to access a Semantic Pointer that does not exist in the vocabulary gives an exception. That can sometimes catch spelling mistakes."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "try:\n",
      "    vocab.parse('UNKNOWN')\n",
      "except spa.exceptions.SpaParseError as err:\n",
      "    print(err)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 35
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In some cases, however, it is more useful to have unknown Semantic Pointers added to the vocabulary automatically. This happens when a vocabulary is created in non-strict mode."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "non_strict_vocab = spa.Vocabulary(32, strict=False)\n",
      "non_strict_vocab.parse('UNKNOWN')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 36
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The default vocabularies in Nengo SPA that are being used whenever you just specify the dimensionality for a module will be in non-strict mode."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Converting between vocabularies\n",
      "\n",
      "When you want to combine Semantic Pointers from different vocabularies in any way, you will need to convert the Semantic Pointers from one vocabulary to the other vocabulary. There are different methods to do so.\n",
      "\n",
      "First, you can use `reinterpret` to indicate that Semantic Pointers from one vocabulary should be interpreted in the context of another vocabulary without any change the actual represented vector. That requires both vocabularies to have the same dimensionality."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with spa.Network() as model:\n",
      "    color = spa.State(just_colors)\n",
      "    state = spa.State(vocab)\n",
      "    spa.reinterpret(color, vocab) >> state"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 37
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Second, you can use 'translate' to find a linear transform that tries to project the Semantic Pointers from one vocabulary to Semantic Pointers in the other vocabulary based on the names. This can be useful to use different dimensionalities for the same Semantic Pointers in different parts of your model."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pointers = 'ONE; TWO; THREE'\n",
      "\n",
      "low_d = spa.Vocabulary(32)\n",
      "low_d.populate(pointers)\n",
      "\n",
      "high_d = spa.Vocabulary(128)\n",
      "high_d.populate(pointers)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 38
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with spa.Network() as model:\n",
      "    low_d_state = spa.State(low_d)\n",
      "    high_d_state = spa.State(high_d)\n",
      "    spa.translate(low_d_state, high_d) >> high_d_state"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 39
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Clean up memories\n",
      "\n",
      "The unbinding of a vector is only an approximate inverse. That means the result will contain some noise that in some cases needs to be removed. This can be done with clean-up or associative memories (a clean-up memory is basically an auto-associative memory). Nengo SPA provides a number of different variants of such associative memories. Here we demonstrate the clean-up with a `ThresholdingAssocMem`. It simply removes all vector components below a certain threshold (here `0.2`).\n",
      "\n",
      "An associative memory needs to be provided with a vocabulary of all potential vectors that it could clean up to. In this example it is the colors `BLUE` and `RED`, but not `CIRCLE` and `SQUARE`. How to create vocabularies has been shown in the previous section. Here we use a slight variation on this. We acquire the *d*-dimension default vocabulary with `model.vocabs[d]` and create subset with the desired vectors from it.\n",
      "\n",
      "Note that this subset is considered to be a different vocabulary than the default vocabulary itself. That means a simple `result >> am` will not work. But we know that both vocabularies use exactly the same vectors (because we created one as subset from the other) and thus can reinterpret the Semantic Pointer from `result` in the subset vocabulary. This is done with `spa.reinterpret(result) >> am`. In this case we do not need to provide the vocabulary as argument to `spa.reinterpret` because it can be determined from the context. Keep in mind that this might not work in all cases and give an exception. Then you have to explicitly add the vocabulary as argument to `spa.reinterpret`."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with spa.Network() as model:\n",
      "    scene = spa.Transcode('BLUE * CIRCLE + RED * SQUARE', output_vocab=d)\n",
      "    query = spa.Transcode(lambda t: 'CIRCLE' if t < 0.25 else 'SQUARE', output_vocab=d)\n",
      "    result = spa.State(d)\n",
      "    am = spa.ThresholdingAssocMem(0.2, model.vocabs[d].create_subset(['BLUE', 'RED']))\n",
      "    \n",
      "    scene * ~query >> result\n",
      "    spa.reinterpret(result) >> am\n",
      "    \n",
      "    p_result = nengo.Probe(result.output, synapse=0.01)\n",
      "    p_am = nengo.Probe(am.output, synapse=0.01)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 53
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with nengo.Simulator(model) as sim:\n",
      "    sim.run(0.5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 54
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.subplot(1, 2, 1)\n",
      "plt.plot(sim.trange(), spa.similarity(sim.data[p_result], model.vocabs[d]))\n",
      "plt.title(\"Before clean-up\")\n",
      "plt.xlabel(\"Time [s]\")\n",
      "plt.ylabel(\"Similarity\")\n",
      "plt.legend(model.vocabs[d], loc='lower left');\n",
      "\n",
      "plt.subplot(1, 2, 2, sharey=plt.gca())\n",
      "plt.plot(sim.trange(), spa.similarity(sim.data[p_am], model.vocabs[d]))\n",
      "plt.title(\"After clean-up\")\n",
      "plt.xlabel(\"Times [s]\");"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 59
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## What is next?\n",
      "\n",
      "This introduction gave a short overview of the core Nengo SPA features. But there is a lot more to most of them. Thus, you might want to delve deeper into certain parts of the documentation that are relevant to you or look at specific examples."
     ]
    }
   ],
   "metadata": {}
  }
 ]
}

